# Compressed-Bio_ClinicalBERT

This project focuses on developing efficient transformer-based models for automated disease diagnosis using clinical text data from the MIMIC-III dataset. 
We fine-tune Bio_ClinicalBERT on structured discharge summaries to classify patient diagnoses, aiming to support clinical decision-making. 
To improve computational efficiency, we apply model compression techniques including pruning, quantization, and knowledge distillation.
Our pipeline maintains strong predictive performance while significantly reducing model size and inference time. 
We evaluate the models using accuracy, F1 score, precision, and recall across training epochs. 
Results show that optimized models can reliably perform disease diagnosis from clinical notes,
making them well-suited for deployment in real-world, resource-limited healthcare settings.

