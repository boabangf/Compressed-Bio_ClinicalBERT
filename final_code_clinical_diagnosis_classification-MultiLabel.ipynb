{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466113a4-f2a5-4292-9298-c46b785a0e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05e458e8eed4a03ab7f388869be6d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcac465066f4414591e06fcf5083badb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 285\u001b[0m\n\u001b[1;32m    283\u001b[0m     train_model(model_quantized)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[43mrun_all\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_all' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "\n",
    "# === Configuration ===\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "max_length = 256\n",
    "epochs = 5\n",
    "prediction_threshold = 0.3\n",
    "temperature = 2.0\n",
    "\n",
    "# === Load and preprocess data ===\n",
    "notes = pd.read_csv(\"NOTEEVENTS_random_chatgpt.csv\")\n",
    "diagnoses = pd.read_csv(\"DIAGNOSES_ICD_random.csv\")\n",
    "\n",
    "notes = notes.dropna(subset=[\"SUBJECT_ID\", \"HADM_ID\", \"TEXT\"])\n",
    "diagnoses = diagnoses.dropna(subset=[\"SUBJECT_ID\", \"HADM_ID\", \"ICD9_CODE\"])\n",
    "diagnoses[\"ICD9_CODE\"] = diagnoses[\"ICD9_CODE\"].astype(str).str[:3]\n",
    "\n",
    "merged = pd.merge(diagnoses, notes, on=[\"SUBJECT_ID\", \"HADM_ID\"], how=\"inner\")\n",
    "grouped = merged.groupby([\"SUBJECT_ID\", \"HADM_ID\"]).agg({\n",
    "    \"TEXT\": \"first\",\n",
    "    \"ICD9_CODE\": lambda x: list(set(x))\n",
    "}).reset_index()\n",
    "\n",
    "from collections import Counter\n",
    "all_codes = [code for codes in grouped[\"ICD9_CODE\"] for code in codes]\n",
    "top_codes = sorted([code for code, _ in Counter(all_codes).most_common(10)])\n",
    "\n",
    "def filter_and_bin(codes, top=top_codes):\n",
    "    filtered = [c for c in codes if c in top]\n",
    "    return filtered if filtered else None\n",
    "\n",
    "def codes_to_multihot(codes, top=top_codes):\n",
    "    return [1 if code in codes else 0 for code in top]\n",
    "\n",
    "grouped[\"filtered_codes\"] = grouped[\"ICD9_CODE\"].apply(filter_and_bin)\n",
    "grouped = grouped.dropna(subset=[\"filtered_codes\"])\n",
    "grouped[\"label_vector\"] = grouped[\"filtered_codes\"].apply(lambda x: codes_to_multihot(x, top_codes))\n",
    "\n",
    "df = grouped[[\"TEXT\", \"label_vector\"]].rename(columns={\"TEXT\": \"text\", \"label_vector\": \"labels\"})\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "eval_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    encoding = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "    encoding[\"labels\"] = examples[\"labels\"]\n",
    "    return encoding\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "eval_dataset = eval_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "eval_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "# Compute class weights for imbalance\n",
    "def compute_class_weights(dataset):\n",
    "    labels = np.stack(dataset[\"labels\"])\n",
    "    label_counts = labels.sum(axis=0)\n",
    "    total = labels.shape[0]\n",
    "    weights = total / (label_counts + 1e-5)\n",
    "    normalized_weights = weights / weights.sum() * len(weights)\n",
    "    return torch.tensor(normalized_weights, dtype=torch.float).to(device)\n",
    "\n",
    "class_weights = compute_class_weights(train_dataset)\n",
    "\n",
    "# Evaluation with AUROC included\n",
    "def evaluate_model(model, loader, threshold=prediction_threshold):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]).logits\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            preds = (probs > threshold).astype(int)\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"micro\", zero_division=0)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    # Compute AUROC per class, then average\n",
    "    try:\n",
    "        auroc_per_class = []\n",
    "        for i in range(all_labels.shape[1]):\n",
    "            if np.sum(all_labels[:, i]) > 0:  # avoid classes with no positive samples\n",
    "                score = roc_auc_score(all_labels[:, i], all_probs[:, i])\n",
    "                auroc_per_class.append(score)\n",
    "        auroc_macro = np.mean(auroc_per_class) if auroc_per_class else 0.0\n",
    "    except Exception:\n",
    "        auroc_macro = 0.0\n",
    "\n",
    "    try:\n",
    "        # Micro AUROC: flatten all\n",
    "        auroc_micro = roc_auc_score(all_labels.ravel(), all_probs.ravel())\n",
    "    except Exception:\n",
    "        auroc_micro = 0.0\n",
    "\n",
    "    return {\n",
    "        \"precision_micro\": precision_micro,\n",
    "        \"recall_micro\": recall_micro,\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"auroc_micro\": auroc_micro,\n",
    "        \"auroc_macro\": auroc_macro,\n",
    "    }\n",
    "\n",
    "# Training function\n",
    "def train_model(model, method_name):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = get_scheduler(\"cosine\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=epochs * len(train_loader))\n",
    "    bce_loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "    csv_file = f\"multilabel_{method_name}_metrics.csv\"\n",
    "    with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Epoch\", \"P_micro\", \"R_micro\", \"F1_micro\", \"P_macro\", \"R_macro\", \"F1_macro\", \"AUROC_micro\", \"AUROC_macro\"])\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "            loss = bce_loss_fn(outputs.logits, batch[\"labels\"].float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        metrics = evaluate_model(model, eval_loader)\n",
    "        with open(csv_file, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                metrics[\"precision_micro\"], metrics[\"recall_micro\"], metrics[\"f1_micro\"],\n",
    "                metrics[\"precision_macro\"], metrics[\"recall_macro\"], metrics[\"f1_macro\"],\n",
    "                metrics[\"auroc_micro\"], metrics[\"auroc_macro\"]\n",
    "            ])\n",
    "        print(f\"{method_name} | Epoch {epoch}/{epochs} - Loss: {total_loss/len(train_loader):.4f} \"\n",
    "              f\"- P_micro: {metrics['precision_micro']:.4f} R_micro: {metrics['recall_micro']:.4f} F1_micro: {metrics['f1_micro']:.4f} \"\n",
    "              f\"- P_macro: {metrics['precision_macro']:.4f} R_macro: {metrics['recall_macro']:.4f} F1_macro: {metrics['f1_macro']:.4f} \"\n",
    "              f\"- AUROC_micro: {metrics['auroc_micro']:.4f} AUROC_macro: {metrics['auroc_macro']:.4f}\")\n",
    "\n",
    "# Models\n",
    "\n",
    "def baseline_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(top_codes),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    ).to(device)\n",
    "    train_model(model, \"baseline\")\n",
    "\n",
    "def pruning_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(top_codes),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    ).to(device)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            import torch.nn.utils.prune as prune\n",
    "            prune.l1_unstructured(module, name=\"weight\", amount=0.3)\n",
    "    train_model(model, \"pruning\")\n",
    "\n",
    "def lowrank_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(top_codes),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    ).to(device)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            weight = module.weight.data\n",
    "            try:\n",
    "                u, s, v = torch.svd_lowrank(weight, q=8)\n",
    "                module.weight.data.copy_((u @ torch.diag(s) @ v.t()).to(weight.device))\n",
    "            except Exception:\n",
    "                pass\n",
    "    train_model(model, \"lowrank\")\n",
    "\n",
    "def distillation_model():\n",
    "    teacher = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(top_codes),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    ).to(device)\n",
    "    teacher.eval()\n",
    "\n",
    "    student = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(top_codes),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(student.parameters(), lr=2e-5)\n",
    "    scheduler = get_scheduler(\"cosine\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=epochs * len(train_loader))\n",
    "    bce_loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "    csv_file = \"multilabel_distillation_metrics.csv\"\n",
    "    with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Epoch\", \"P_micro\", \"R_micro\", \"F1_micro\", \"P_macro\", \"R_macro\", \"F1_macro\", \"AUROC_micro\", \"AUROC_macro\"])\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        student.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]).logits\n",
    "\n",
    "            student_logits = student(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]).logits\n",
    "\n",
    "            ce_loss = bce_loss_fn(student_logits, batch[\"labels\"].float())\n",
    "\n",
    "            T = temperature\n",
    "            student_log_prob = F.log_softmax(student_logits / T, dim=1)\n",
    "            teacher_prob = F.softmax(teacher_logits / T, dim=1)\n",
    "            kd_loss = F.kl_div(student_log_prob, teacher_prob, reduction=\"batchmean\") * (T * T)\n",
    "\n",
    "            loss = 0.1 * ce_loss + 0.9 * kd_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        metrics = evaluate_model(student, eval_loader)\n",
    "        with open(csv_file, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                metrics[\"precision_micro\"], metrics[\"recall_micro\"], metrics[\"f1_micro\"],\n",
    "                metrics[\"precision_macro\"], metrics[\"recall_macro\"], metrics[\"f1_macro\"],\n",
    "                metrics[\"auroc_micro\"], metrics[\"auroc_macro\"]\n",
    "            ])\n",
    "        print(f\"Distillation | Epoch {epoch}/{epochs} - Loss: {total_loss/len(train_loader):.4f} \"\n",
    "              f\"- P_micro: {metrics['precision_micro']:.4f} R_micro: {metrics['recall_micro']:.4f} F1_micro: {metrics['f1_micro']:.4f} \"\n",
    "              f\"- P_macro: {metrics['precision_macro']:.4f} R_macro: {metrics['recall_macro']:.4f} F1_macro: {metrics['f1_macro']:.4f} \"\n",
    "              f\"- AUROC_micro: {metrics['auroc_micro']:.4f} AUROC_macro: {metrics['auroc_macro']:.4f}\")\n",
    "\n",
    "def quantization_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(top_codes),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "    model.to(\"cpu\")\n",
    "    model.eval()\n",
    "    model_quantized = torch.quantization.quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n",
    "    model_quantized.to(device)\n",
    "    train_model(model_quantized)\n",
    "if __name__ == \"__main__\":\n",
    "    run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a9fcd-eab2-4386-948d-2b7508d1f6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
